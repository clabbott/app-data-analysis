10/28 
Meeting about moving forward with project. 
Before next meeting: put a notebook in the repo, start data collection. :)
11/4
Uploaded initial python Jupyter Notebook project files
Have not started data collection
11/8
Scraped data from datafile, included datafile in repo, wrote up plan to clean data in file
11/16
General Changes:
Imported Numpy
Dataframe originally read from archive file? Changed it to simply the csv file for now.

App Column (Cleaning Database):
Dropped malformed data: "Life Made WI-Fi Touchscreen Photo Frame"
Dropped exact duplicate names.

Reviews Column (Cleaning Database):
Converted to numeric

Size Column (Cleaning Database):
Replaced "Varies with device" value with NaN. 
Converted strings to kb.
12/11
Cleaned the rest of the dataframe except for the genres column 
Might have submitted the Jupyter in a weird way, trying to fix that on the submit for 12/12 
12/12
Formatted everything to make it a bit more organized.
Added introduction. Separated data collection into it's own code block and also gave it a blurb.
Based my writing off the examples in the syllabus. Prose makes up a good amount of our grade so lmk what you think.
We can change it if our project develops as we look more into data.

I've left Data Processing as it is for now. I think splitting up the huge blocks for column may be easier on the eyes.
Also I understand why genre and content rating are split like they are, but I'm worried Teli may expect a "Tidy" dataset for that part.
I can do some of this stuff myself, just wanted your opinion before I messed with what you have.

Graphing was a lot harder than I thought it would be. There are a few directions we could go.
Explained more in the notebook.

12/12
Did a lot of potential exploratory analysis with the aim to compare reviews and installs. 
Separated the dataframes: 
df- dataframe containing no duplicates, apps with multiple genres will only appear once with one of their genres. 
  Use this when comparing the entire dataframe but not the genres.
genre_df- dataframe containing duplicates, apps with multiple genres will appear twice. Do not use this for analysis of the entire dataframe.
ml_df- dataframe containing no duplicates but dummy variables for content rating and genres. Use for machine learning. May not be tidy according to teli's standards. 
Did a simple and poor linear regresion line on "Installs vs Review"
Thoughts: 
- Would eliminating outliers make the data easier to use? 
- What is our target variable that we want to predict? 
More info in notebook
12/13
Created three new chart groups playing around with a more categorical approach to installs.
1st chart is a pie chart that breaks down 10^x bucket percentage which is used to inform the other charts.
2nd and 3rd look at how rating and category change at different install percentiles.
The results are a bit disappointing, but still useful.
Rating distributions only change slightly with minimums and outliers. Category changes with some categories being left of higher percentiles, but still similar across the board.
Overall, I think what little atributes we have aren't decisive enough to make a decision tree.
Ratings being our target variable might be our best bet.
12/15 (early morning)
Did most of data exploration a little behind schedule. Feel free to insert your analysis anywhere in there where you think it would fit, I was just going over all the variables
and how they interact. Today I will finish up the exploration and let you take a shot at ML first because you had some good ideas. More in the doc. 
12/15 (afternoon)
Finished up data exploration except for rating and comparing installs/reviews. You had a really good take on those variables, could you cover those tonight? 
We hit a gold mine with the "Last Updated" variable, theres a clear trend for apps to do better the more recently they were updated. That will be very useful in ML. 
Ratings turned out to be a bust, its the same for everything, just a straight average of 4.1ish. Depending on what you find out with comparing reviews and installs,
I think trying to predict number of installs is our best bet. 
